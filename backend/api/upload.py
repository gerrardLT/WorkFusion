"""
å¤šåœºæ™¯æ–‡ä»¶ä¸Šä¼ APIè·¯ç”±
"""

import os
import sys
import uuid
from pathlib import Path
from typing import Optional, List
from fastapi import APIRouter, HTTPException, UploadFile, File, Form, Depends
from fastapi.background import BackgroundTasks

# æ·»åŠ srcè·¯å¾„ä»¥ä½¿ç”¨Pipeline
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from ..services.scenario_service import get_scenario_service, ScenarioService
from ..services.document_service import get_document_service, DocumentService
from ..services.progress_manager import get_progress_manager
from ..services.checklist_service import get_checklist_service
from ..middleware.auth_middleware import get_current_user, get_current_tenant, get_current_user_id
from .models import UploadResponse, ProcessingStatus
import logging

logger = logging.getLogger(__name__)

# å¯¼å…¥Pipelineç›¸å…³
try:
    # å°è¯•å¯¼å…¥Pipelineç›¸å…³æ¨¡å—
    from src.pipeline import Pipeline, RunConfig
    # ç›´æ¥ä»src.configæ¨¡å—å¯¼å…¥get_settings
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))
    from config import get_settings
    PIPELINE_AVAILABLE = True
    print("[OK] Pipelineé›†æˆå·²å¯ç”¨")
except ImportError as e:
    print(f"âš ï¸ Pipelineå¯¼å…¥å¤±è´¥: {e}")
    PIPELINE_AVAILABLE = False

router = APIRouter(prefix="/upload", tags=["upload"])

# ä¸Šä¼ æ–‡ä»¶å­˜å‚¨ç›®å½•
UPLOAD_DIR = Path("data/uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)


def generate_filename(original_filename: str, scenario_id: str) -> str:
    """ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å"""
    file_ext = Path(original_filename).suffix
    unique_id = str(uuid.uuid4())[:8]
    return f"{scenario_id}_{unique_id}_{original_filename}"


def generate_checklist_background(document_id: str, scenario_id: str):
    """åå°ä»»åŠ¡ï¼šä¸ºæ–‡æ¡£ç”ŸæˆChecklist"""
    try:
        logger.info(f"ğŸ”„ å¼€å§‹ä¸ºæ–‡æ¡£ {document_id} ç”Ÿæˆä»»åŠ¡æ¸…å•ï¼ˆåå°ä»»åŠ¡ï¼‰")

        checklist_service = get_checklist_service()
        checklist_id = checklist_service.generate_checklist(
            document_id=document_id,
            scenario_id=scenario_id
        )

        if checklist_id:
            logger.info(f"[OK] æ–‡æ¡£ {document_id} çš„ä»»åŠ¡æ¸…å•ç”ŸæˆæˆåŠŸ: {checklist_id}")
        else:
            logger.error(f"[ERROR] æ–‡æ¡£ {document_id} çš„ä»»åŠ¡æ¸…å•ç”Ÿæˆå¤±è´¥")

    except Exception as e:
        logger.error(f"[ERROR] åå°ç”Ÿæˆä»»åŠ¡æ¸…å•å¤±è´¥: {str(e)}", exc_info=True)


def process_document_sync(
    document_id: str,
    file_path: str,
    scenario_id: str,
    document_service: DocumentService,
    tenant_id: str = "default"  # æ–°å¢ï¼šç§Ÿæˆ·IDå‚æ•°
) -> dict:
    """
    åŒæ­¥å¤„ç†æ–‡æ¡£å¹¶è¿”å›ç»“æœï¼ˆåªå¤„ç†æœ¬æ¬¡ä¸Šä¼ çš„æ–‡ä»¶ï¼‰

    Args:
        document_id: æ–‡æ¡£ID
        file_path: æ–‡ä»¶è·¯å¾„
        scenario_id: åœºæ™¯ID
        document_service: æ–‡æ¡£æœåŠ¡
        tenant_id: ç§Ÿæˆ·IDï¼ˆç”¨äºç´¢å¼•éš”ç¦»ï¼‰
    """
    progress_manager = get_progress_manager()

    try:
        # å¼€å§‹å¤„ç†æ–‡æ¡£
        progress_manager.update_progress(
            document_id,
            stage='parsing',
            progress=0,
            message='å¼€å§‹å¤„ç†æ–‡æ¡£...'
        )

        # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
        document_service.update_document_status(document_id, "processing")

        if not PIPELINE_AVAILABLE:
            # Pipelineä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡ŒçœŸå®æ–‡æ¡£å¤„ç†
            document_service.update_document_status(document_id, "failed")
            return {
                "success": False,
                "message": "Pipelineä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæ–‡æ¡£å¤„ç†",
                "chunks_created": 0,
                "vectors_created": 0
            }

        # ğŸ”§ ä½¿ç”¨å•æ–‡ä»¶å¤„ç†æ¨¡å¼ï¼ˆåªå¤„ç†æœ¬æ¬¡ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä¸é‡å¤å¤„ç†å†å²æ–‡ä»¶ï¼‰
        from src.pdf_parsing_mineru import PDFParsingPipeline
        from src.ingestion import IngestionPipeline

        settings = get_settings()
        data_dir = settings.data_dir

        # è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆç§Ÿæˆ·çº§éš”ç¦»ï¼‰
        parsed_output_dir = data_dir / "debug_data" / "parsed_reports"
        vector_output_dir = data_dir / "databases" / "vector_dbs" / tenant_id / scenario_id
        bm25_output_dir = data_dir / "databases" / "bm25" / tenant_id / scenario_id

        parsed_output_dir.mkdir(parents=True, exist_ok=True)
        vector_output_dir.mkdir(parents=True, exist_ok=True)
        bm25_output_dir.mkdir(parents=True, exist_ok=True)

        print(f"[INFO] ç§Ÿæˆ·çº§ç´¢å¼•ç›®å½•:")
        print(f"  å‘é‡ç´¢å¼•: {vector_output_dir}")
        print(f"  BM25ç´¢å¼•: {bm25_output_dir}")

        # 1ï¸âƒ£ è§£ææœ¬æ¬¡ä¸Šä¼ çš„PDFæ–‡ä»¶ï¼ˆä½¿ç”¨MinerUï¼‰
        print(f"ğŸ“„ å¼€å§‹è§£æPDF: {Path(file_path).name}")

        # åˆ›å»ºè¿›åº¦å›è°ƒå‡½æ•°
        def progress_callback(stage, progress, message, total_pages=None, current_page=None):
            progress_manager.update_progress(
                document_id,
                stage=stage,
                progress=progress,
                message=message,
                total_pages=total_pages,
                current_page=current_page
            )

        pdf_parser = PDFParsingPipeline(scenario_id=scenario_id, progress_callback=progress_callback)
        success, parse_result = pdf_parser.parse_pdf_file(
            str(file_path),
            str(parsed_output_dir)
        )

        if not success:
            document_service.update_document_status(document_id, "failed")
            return {
                "success": False,
                "message": f"PDFè§£æå¤±è´¥: {parse_result.get('error', 'Unknown error')}",
                "chunks_created": 0,
                "vectors_created": 0
            }

        print(f"[OK] PDFè§£æå®Œæˆ")

        # 2ï¸âƒ£ å¯¹æœ¬æ¬¡ä¸Šä¼ çš„æ–‡ä»¶è¿›è¡Œå‘é‡åŒ–å’ŒBM25ç´¢å¼•
        print(f"ğŸ”¢ å¼€å§‹å‘é‡åŒ–å¤„ç†...")

        # æ›´æ–°è¿›åº¦ï¼šå¼€å§‹å‘é‡åŒ–
        progress_manager.update_progress(
            document_id,
            stage='vectorizing',
            progress=35,
            message='å¼€å§‹å‘é‡åŒ–å¤„ç†...'
        )

        # è·å–è§£æç»“æœ
        parsed_data = parse_result["parsed_result"]

        # åˆ›å»ºå‘é‡åŒ–å’ŒBM25ç´¢å¼•
        ingestion = IngestionPipeline(api_provider="dashscope")

        # å‘é‡åŒ–
        progress_manager.update_progress(
            document_id,
            stage='vectorizing',
            progress=50,
            message='æ­£åœ¨ç”Ÿæˆå‘é‡ç´¢å¼•...'
        )

        vector_success, vector_result = ingestion.vector_ingestor.process_single_report(
            parsed_data,
            vector_output_dir
        )

        # BM25ç´¢å¼•
        progress_manager.update_progress(
            document_id,
            stage='vectorizing',
            progress=75,
            message='æ­£åœ¨ç”Ÿæˆ BM25 ç´¢å¼•...'
        )

        bm25_success, bm25_result = ingestion.bm25_ingestor.process_single_report(
            parsed_data,
            bm25_output_dir
        )

        print(f"[OK] å‘é‡åŒ–å®Œæˆ: vector={vector_success}, bm25={bm25_success}")

        # ç»Ÿè®¡æ–‡æ¡£å—æ•°é‡
        chunks_created = len(parsed_data.get("pages", []))

        # æ›´æ–°æ–‡æ¡£çŠ¶æ€
        if vector_success and bm25_success:
            document_service.update_document_status(document_id, "completed", quality_score=0.9)
            status = "completed"
            message = "æ–‡æ¡£å¤„ç†å®Œæˆ"
        else:
            document_service.update_document_status(document_id, "completed", quality_score=0.6)
            status = "partial"
            message = "æ–‡æ¡£å¤„ç†éƒ¨åˆ†å®Œæˆ"

        # æ›´æ–°è¿›åº¦ï¼šå®Œæˆ
        progress_manager.update_progress(
            document_id,
            stage='completed',
            progress=100,
            message='æ–‡æ¡£å¤„ç†å®Œæˆï¼'
        )

        result = {
            "success": True,
            "message": message,
            "status": status,
            "chunks_created": chunks_created,
            "vectors_created": 1 if vector_success else 0,
            "bm25_created": 1 if bm25_success else 0,
            "processing_details": {
                "file_id": parse_result.get("file_id"),
                "parsed_output": parse_result.get("output_path"),
                "vector_output": vector_result if vector_success else None,
                "bm25_output": bm25_result if bm25_success else None
            }
        }

        print(f"[OK] æ–‡æ¡£å¤„ç†å®Œæˆ: {Path(file_path).name}")
        return result

    except Exception as e:
        # æ–‡æ¡£å¤„ç†å¤±è´¥
        import traceback
        traceback.print_exc()

        # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
        document_service.update_document_status(document_id, "failed")

        # æ›´æ–°è¿›åº¦ï¼šé”™è¯¯
        progress_manager.update_progress(
            document_id,
            stage='error',
            progress=0,
            message=f'å¤„ç†å¤±è´¥: {str(e)}'
        )

        return {
            "success": False,
            "message": f"æ–‡æ¡£å¤„ç†å¤±è´¥: {str(e)}",
            "chunks_created": 0,
            "vectors_created": 0
        }


@router.post("/")
async def upload_file(
    file: UploadFile = File(...),
    scenario_id: str = Form(...),
    title: Optional[str] = Form(None),
    background_tasks: BackgroundTasks = None,
    current_user: dict = Depends(get_current_user),
    tenant_id: str = Depends(get_current_tenant),
    user_id: str = Depends(get_current_user_id),
    scenario_service: ScenarioService = Depends(get_scenario_service),
    document_service: DocumentService = Depends(get_document_service)
):
    """
    ä¸Šä¼ å•ä¸ªæ–‡ä»¶åˆ°æŒ‡å®šåœºæ™¯å¹¶åŒæ­¥å¤„ç†

    éœ€è¦è®¤è¯ï¼Œæ–‡æ¡£è‡ªåŠ¨å…³è”åˆ°å½“å‰ç§Ÿæˆ·å’Œç”¨æˆ·
    """
    try:
        print(f"[INFO] ç”¨æˆ· {current_user['username']} (ç§Ÿæˆ·: {tenant_id}) ä¸Šä¼ æ–‡ä»¶: {file.filename}")

        # éªŒè¯åœºæ™¯
        if not scenario_service.validate_scenario(scenario_id):
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆåœºæ™¯: {scenario_id}")

        # æ£€æŸ¥æ–‡ä»¶
        if not file.filename:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶åä¸èƒ½ä¸ºç©º")

        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        allowed_extensions = ['.pdf', '.txt', '.docx', '.doc']
        file_ext = Path(file.filename).suffix.lower()
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}ã€‚æ”¯æŒçš„ç±»å‹: {', '.join(allowed_extensions)}"
            )

        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_content = await file.read()
        file_size = len(file_content)

        if file_size == 0:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶ä¸èƒ½ä¸ºç©º")

        # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶ (50MB)
        max_size = 50 * 1024 * 1024  # 50MB
        if file_size > max_size:
            raise HTTPException(status_code=400, detail=f"æ–‡ä»¶è¿‡å¤§: {file_size/1024/1024:.1f}MBï¼Œæœ€å¤§æ”¯æŒ50MB")

        # ç”Ÿæˆç§Ÿæˆ·çº§æ–‡ä»¶è·¯å¾„ï¼ˆé¿å…æ–‡ä»¶åå†²çªï¼‰
        filename = f"{tenant_id}_{generate_filename(file.filename, scenario_id)}"
        file_path = UPLOAD_DIR / filename

        # ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(file_content)

        print(f"[OK] æ–‡ä»¶å·²ä¿å­˜: {file_path}")

        # å¤„ç†æ–‡æ¡£å…ƒæ•°æ®
        document_title = title or file.filename
        document_id = document_service.process_document(
            scenario_id=scenario_id,
            file_path=str(file_path),
            title=document_title,
            file_size=file_size,
            additional_metadata={
                "original_filename": file.filename,
                "upload_filename": filename,
                "file_extension": file_ext,
                "tenant_id": tenant_id,  # æ–°å¢ï¼šç§Ÿæˆ·ä¿¡æ¯
                "uploaded_by": user_id   # æ–°å¢ï¼šä¸Šä¼ è€…ä¿¡æ¯
            }
        )

        if not document_id:
            # åˆ é™¤å·²ä¿å­˜çš„æ–‡ä»¶
            if file_path.exists():
                os.remove(file_path)
            raise HTTPException(status_code=500, detail="æ–‡æ¡£å…ƒæ•°æ®å¤„ç†å¤±è´¥")

        # æ–‡æ¡£è®°å½•å·²åˆ›å»º

        # åŒæ­¥å¤„ç†æ–‡æ¡£ï¼ˆPDFè§£æ + å‘é‡åŒ–ï¼‰
        # æ³¨æ„ï¼šéœ€è¦ä¼ é€’tenant_idä»¥å®ç°ç§Ÿæˆ·çº§ç´¢å¼•éš”ç¦»
        processing_result = process_document_sync(
            document_id,
            str(file_path),
            scenario_id,
            document_service,
            tenant_id=tenant_id  # æ–°å¢ï¼šç§Ÿæˆ·IDç”¨äºç´¢å¼•éš”ç¦»
        )

        # ã€æ–°å¢ã€‘å¦‚æœæ–‡æ¡£å¤„ç†æˆåŠŸï¼Œä¸”æ˜¯æ‹›æŠ•æ ‡åœºæ™¯ï¼Œè‡ªåŠ¨ç”ŸæˆChecklist
        if processing_result["success"] and scenario_id == "tender" and background_tasks:
            logger.info(f"ğŸ“‹ æ–‡æ¡£å¤„ç†æˆåŠŸï¼Œæ·»åŠ Checklistç”Ÿæˆä»»åŠ¡åˆ°åå°é˜Ÿåˆ—")
            background_tasks.add_task(
                generate_checklist_background,
                document_id,
                scenario_id
            )

        # æ„å»ºå“åº”
        response = {
            "success": processing_result["success"],
            "message": processing_result["message"],
            "document_id": document_id,
            "filename": file.filename,
            "file_size": file_size,
            "file_size_mb": round(file_size / 1024 / 1024, 2),
            "scenario_id": scenario_id,
            "processing_stats": {
                "chunks_created": processing_result.get("chunks_created", 0),
                "vectors_created": processing_result.get("vectors_created", 0),
                "pipeline_ready": processing_result.get("pipeline_ready", False)
            },
            "checklist_generation": "queued" if (processing_result["success"] and scenario_id == "tender") else "skipped"
        }

        return response

    except HTTPException:
        raise
    except Exception as e:
        # æ¸…ç†æ–‡ä»¶
        if 'file_path' in locals() and Path(file_path).exists():
            os.remove(file_path)

        import traceback
        print(f"[ERROR] ä¸Šä¼ å¤„ç†å¤±è´¥: {str(e)}")
        traceback.print_exc()

        raise HTTPException(status_code=500, detail=f"ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.get("/status/{document_id}", response_model=ProcessingStatus)
async def get_processing_status(
    document_id: str,
    document_service: DocumentService = Depends(get_document_service)
):
    """è·å–æ–‡æ¡£å¤„ç†çŠ¶æ€"""
    try:
        document = document_service.get_document(document_id)

        if not document:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

        # è®¡ç®—è¿›åº¦
        progress = 0.0
        if document["status"] == "pending":
            progress = 0.0
        elif document["status"] == "processing":
            progress = 0.5
        elif document["status"] == "completed":
            progress = 1.0
        elif document["status"] == "failed":
            progress = 0.0

        return ProcessingStatus(
            document_id=document_id,
            status=document["status"],
            progress=progress,
            message=f"æ–‡æ¡£{document['status']}",
            created_at=document["created_at"],
            updated_at=document["updated_at"]
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å¤„ç†çŠ¶æ€å¤±è´¥: {str(e)}")


@router.get("/documents")
async def get_documents(
    scenario_id: Optional[str] = None,
    limit: int = 50,
    current_user: dict = Depends(get_current_user),
    tenant_id: str = Depends(get_current_tenant),
    scenario_service: ScenarioService = Depends(get_scenario_service),
    document_service: DocumentService = Depends(get_document_service)
):
    """
    è·å–æ–‡æ¡£åˆ—è¡¨

    éœ€è¦è®¤è¯ï¼Œä»…è¿”å›å½“å‰ç§Ÿæˆ·çš„æ–‡æ¡£
    """
    try:
        if scenario_id:
            # éªŒè¯åœºæ™¯
            if not scenario_service.validate_scenario(scenario_id):
                raise HTTPException(status_code=400, detail=f"æ— æ•ˆåœºæ™¯: {scenario_id}")

            # TODO: éœ€è¦ä¿®æ”¹document_serviceä»¥æ”¯æŒç§Ÿæˆ·è¿‡æ»¤
            # documents = document_service.get_documents_by_scenario_and_tenant(scenario_id, tenant_id, limit)
            documents = document_service.get_documents_by_scenario(scenario_id, limit)

            # ä¸´æ—¶è¿‡æ»¤ï¼šä»…è¿”å›å½“å‰ç§Ÿæˆ·çš„æ–‡æ¡£
            # æ³¨æ„ï¼šè¿™æ˜¯ä¸´æ—¶æ–¹æ¡ˆï¼Œåº”è¯¥åœ¨æ•°æ®åº“æŸ¥è¯¢å±‚é¢å®ç°è¿‡æ»¤
            filtered_documents = []
            for doc in documents:
                if hasattr(doc, 'tenant_id') and doc.tenant_id == tenant_id:
                    filtered_documents.append(doc)
                elif not hasattr(doc, 'tenant_id'):
                    # å…¼å®¹æ—§æ•°æ®ï¼ˆæ²¡æœ‰tenant_idçš„æ–‡æ¡£ï¼‰
                    filtered_documents.append(doc)

            documents = filtered_documents
        else:
            # è·å–å½“å‰ç§Ÿæˆ·çš„æ‰€æœ‰æ–‡æ¡£
            # TODO: éœ€è¦å®ç°get_documents_by_tenantæ–¹æ³•
            documents = []

        print(f"[INFO] ç”¨æˆ· {current_user['username']} è·å–æ–‡æ¡£åˆ—è¡¨: {len(documents)} ä¸ªæ–‡æ¡£")

        return {
            "documents": documents,
            "total": len(documents),
            "scenario_id": scenario_id,
            "tenant_id": tenant_id
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {str(e)}")


@router.post("/batch")
async def upload_files_batch(
    files: List[UploadFile] = File(...),
    scenario_id: str = Form(...),
    current_user: dict = Depends(get_current_user),
    tenant_id: str = Depends(get_current_tenant),
    user_id: str = Depends(get_current_user_id),
    scenario_service: ScenarioService = Depends(get_scenario_service),
    document_service: DocumentService = Depends(get_document_service)
):
    """
    æ‰¹é‡ä¸Šä¼ æ–‡ä»¶åˆ°æŒ‡å®šåœºæ™¯å¹¶åŒæ­¥å¤„ç†ï¼ˆåªå¤„ç†æœ¬æ¬¡ä¸Šä¼ çš„æ–‡ä»¶ï¼‰

    éœ€è¦è®¤è¯ï¼Œæ–‡æ¡£è‡ªåŠ¨å…³è”åˆ°å½“å‰ç§Ÿæˆ·å’Œç”¨æˆ·
    """
    try:
        print(f"[INFO] ç”¨æˆ· {current_user['username']} (ç§Ÿæˆ·: {tenant_id}) æ‰¹é‡ä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶")

        # éªŒè¯åœºæ™¯
        if not scenario_service.validate_scenario(scenario_id):
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆåœºæ™¯: {scenario_id}")

        if not files:
            raise HTTPException(status_code=400, detail="æœªé€‰æ‹©æ–‡ä»¶")

        print(f"[INFO] æ‰¹é‡ä¸Šä¼  {len(files)} ä¸ªæ–‡ä»¶åˆ°åœºæ™¯ {scenario_id}")

        results = []
        successful = 0
        failed = 0

        # å¤„ç†æ¯ä¸ªä¸Šä¼ çš„æ–‡ä»¶
        for file in files:
            try:
                # æ£€æŸ¥æ–‡ä»¶
                if not file.filename:
                    results.append({
                        "filename": "unknown",
                        "success": False,
                        "error": "æ–‡ä»¶åä¸èƒ½ä¸ºç©º"
                    })
                    failed += 1
                    continue

                # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                allowed_extensions = ['.pdf', '.txt', '.docx', '.doc']
                file_ext = Path(file.filename).suffix.lower()
                if file_ext not in allowed_extensions:
                    results.append({
                        "filename": file.filename,
                        "success": False,
                        "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}"
                    })
                    failed += 1
                    continue

                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_content = await file.read()
                file_size = len(file_content)

                if file_size == 0:
                    results.append({
                        "filename": file.filename,
                        "success": False,
                        "error": "æ–‡ä»¶ä¸èƒ½ä¸ºç©º"
                    })
                    failed += 1
                    continue

                max_size = 50 * 1024 * 1024  # 50MB
                if file_size > max_size:
                    results.append({
                        "filename": file.filename,
                        "success": False,
                        "error": f"æ–‡ä»¶è¿‡å¤§: {file_size/1024/1024:.1f}MB"
                    })
                    failed += 1
                    continue

                # ç”Ÿæˆç§Ÿæˆ·çº§æ–‡ä»¶è·¯å¾„å¹¶ä¿å­˜
                filename = f"{tenant_id}_{generate_filename(file.filename, scenario_id)}"
                file_path = UPLOAD_DIR / filename

                with open(file_path, "wb") as f:
                    f.write(file_content)

                print(f"[OK] æ–‡ä»¶å·²ä¿å­˜: {file.filename}")

                # å¤„ç†æ–‡æ¡£å…ƒæ•°æ®
                document_id = document_service.process_document(
                    scenario_id=scenario_id,
                    file_path=str(file_path),
                    title=file.filename,
                    file_size=file_size,
                    additional_metadata={
                        "original_filename": file.filename,
                        "upload_filename": filename,
                        "file_extension": file_ext,
                        "batch_upload": True,
                        "tenant_id": tenant_id,  # æ–°å¢ï¼šç§Ÿæˆ·ä¿¡æ¯
                        "uploaded_by": user_id   # æ–°å¢ï¼šä¸Šä¼ è€…ä¿¡æ¯
                    }
                )

                if not document_id:
                    if file_path.exists():
                        os.remove(file_path)
                    results.append({
                        "filename": file.filename,
                        "success": False,
                        "error": "æ–‡æ¡£å…ƒæ•°æ®å¤„ç†å¤±è´¥"
                    })
                    failed += 1
                    continue

                # åŒæ­¥å¤„ç†æ–‡æ¡£ï¼ˆä¼ é€’ç§Ÿæˆ·IDç”¨äºç´¢å¼•éš”ç¦»ï¼‰
                processing_result = process_document_sync(
                    document_id,
                    str(file_path),
                    scenario_id,
                    document_service,
                    tenant_id=tenant_id  # æ–°å¢ï¼šç§Ÿæˆ·IDç”¨äºç´¢å¼•éš”ç¦»
                )

                results.append({
                    "filename": file.filename,
                    "success": processing_result["success"],
                    "document_id": document_id,
                    "file_size_mb": round(file_size / 1024 / 1024, 2),
                    "chunks_created": processing_result.get("chunks_created", 0),
                    "vectors_created": processing_result.get("vectors_created", 0),
                    "message": processing_result.get("message", "")
                })

                if processing_result["success"]:
                    successful += 1
                    print(f"[OK] {file.filename} å¤„ç†æˆåŠŸ")
                else:
                    failed += 1
                    print(f"[ERROR] {file.filename} å¤„ç†å¤±è´¥")

            except Exception as e:
                results.append({
                    "filename": file.filename if file.filename else "unknown",
                    "success": False,
                    "error": str(e)
                })
                failed += 1
                print(f"[ERROR] {file.filename} å¤„ç†å¼‚å¸¸: {str(e)}")

        return {
            "success": failed == 0,
            "total": len(files),
            "successful": successful,
            "failed": failed,
            "results": results,
            "scenario_id": scenario_id,
            "message": f"æ‰¹é‡ä¸Šä¼ å®Œæˆ: æˆåŠŸ {successful}/{len(files)}"
        }

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡ä¸Šä¼ å¤±è´¥: {str(e)}")


@router.get("/progress/{document_id}")
async def get_upload_progress(document_id: str):
    """è·å–æ–‡æ¡£å¤„ç†è¿›åº¦

    Args:
        document_id: æ–‡æ¡£ID

    Returns:
        è¿›åº¦ä¿¡æ¯
    """
    progress_manager = get_progress_manager()
    progress = progress_manager.get_progress(document_id)

    if progress is None:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°è¯¥æ–‡æ¡£çš„è¿›åº¦ä¿¡æ¯")

    return progress


@router.delete("/documents/{document_id}")
async def delete_document(
    document_id: str,
    document_service: DocumentService = Depends(get_document_service)
):
    """åˆ é™¤æ–‡æ¡£"""
    try:
        # è·å–æ–‡æ¡£ä¿¡æ¯
        document = document_service.get_document(document_id)
        if not document:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

        # åˆ é™¤æ–‡ä»¶
        file_path = Path(document["file_path"])
        if file_path.exists():
            os.remove(file_path)

        # åˆ é™¤æ•°æ®åº“è®°å½•
        success = document_service.delete_document(document_id)

        if not success:
            raise HTTPException(status_code=500, detail="åˆ é™¤æ–‡æ¡£å¤±è´¥")

        # æ¸…ç†è¿›åº¦ä¿¡æ¯
        progress_manager = get_progress_manager()
        progress_manager.remove_progress(document_id)

        return {"message": "æ–‡æ¡£åˆ é™¤æˆåŠŸ"}

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {str(e)}")
