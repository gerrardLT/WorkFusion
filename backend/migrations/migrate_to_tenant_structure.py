#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šå°†ç°æœ‰ç´¢å¼•æ–‡ä»¶è¿ç§»åˆ°ç§Ÿæˆ·çº§ç›®å½•ç»“æ„

è¿ç§»å†…å®¹ï¼š
1. å‘é‡æ•°æ®åº“ç´¢å¼•æ–‡ä»¶ (FAISS)
2. BM25ç´¢å¼•æ–‡ä»¶
3. ç›¸å…³å…ƒæ•°æ®æ–‡ä»¶

è¿ç§»å‰ç»“æ„ï¼š
data/stock_data/databases/
â”œâ”€â”€ vector_dbs/
â”‚   â”œâ”€â”€ tender.index
â”‚   â”œâ”€â”€ enterprise.index
â”‚   â””â”€â”€ ...
â””â”€â”€ bm25/
    â”œâ”€â”€ tender_bm25.pkl
    â”œâ”€â”€ enterprise_bm25.pkl
    â””â”€â”€ ...

è¿ç§»åç»“æ„ï¼š
data/stock_data/databases/
â”œâ”€â”€ vector_dbs/
â”‚   â””â”€â”€ default/
â”‚       â”œâ”€â”€ tender/
â”‚       â”‚   â””â”€â”€ tender.index
â”‚       â””â”€â”€ enterprise/
â”‚           â””â”€â”€ enterprise.index
â””â”€â”€ bm25/
    â””â”€â”€ default/
        â”œâ”€â”€ tender/
        â”‚   â””â”€â”€ tender_bm25.pkl
        â””â”€â”€ enterprise/
            â””â”€â”€ enterprise_bm25.pkl
"""

import os
import sys
import shutil
import logging
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.config import get_settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f'migration_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    ]
)
logger = logging.getLogger(__name__)

# é»˜è®¤ç§Ÿæˆ·ID
DEFAULT_TENANT_ID = "default"

# æ”¯æŒçš„åœºæ™¯åˆ—è¡¨
SCENARIOS = ["tender", "enterprise", "admin", "finance", "procurement", "engineering"]


class TenantStructureMigrator:
    """ç§Ÿæˆ·ç»“æ„è¿ç§»å™¨"""

    def __init__(self, data_dir: Path = None, dry_run: bool = False):
        """åˆå§‹åŒ–è¿ç§»å™¨

        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…ç§»åŠ¨æ–‡ä»¶ï¼‰
        """
        self.settings = get_settings()
        self.data_dir = data_dir or self.settings.data_dir
        self.dry_run = dry_run

        # å…³é”®ç›®å½•è·¯å¾„
        self.databases_dir = self.data_dir / "databases"
        self.vector_dbs_dir = self.databases_dir / "vector_dbs"
        self.bm25_dir = self.databases_dir / "bm25"

        # è¿ç§»ç»Ÿè®¡
        self.migration_stats = {
            "vector_files_moved": 0,
            "bm25_files_moved": 0,
            "metadata_files_moved": 0,
            "directories_created": 0,
            "errors": []
        }

        logger.info(f"è¿ç§»å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"æ•°æ®ç›®å½•: {self.data_dir}")
        logger.info(f"è¯•è¿è¡Œæ¨¡å¼: {self.dry_run}")

    def check_prerequisites(self) -> bool:
        """æ£€æŸ¥è¿ç§»å‰ææ¡ä»¶

        Returns:
            æ˜¯å¦æ»¡è¶³è¿ç§»æ¡ä»¶
        """
        logger.info("æ£€æŸ¥è¿ç§»å‰ææ¡ä»¶...")

        # æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨
        if not self.data_dir.exists():
            logger.error(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_dir}")
            return False

        if not self.databases_dir.exists():
            logger.error(f"æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {self.databases_dir}")
            return False

        # æ£€æŸ¥æ˜¯å¦å·²ç»è¿ç§»è¿‡
        default_tenant_dir = self.vector_dbs_dir / DEFAULT_TENANT_ID
        if default_tenant_dir.exists():
            logger.warning(f"æ£€æµ‹åˆ°é»˜è®¤ç§Ÿæˆ·ç›®å½•å·²å­˜åœ¨: {default_tenant_dir}")
            logger.warning("å¯èƒ½å·²ç»è¿ç§»è¿‡ï¼Œè¯·ç¡®è®¤æ˜¯å¦éœ€è¦é‡æ–°è¿ç§»")

            # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
            if not self.dry_run:
                response = input("æ˜¯å¦ç»§ç»­è¿ç§»ï¼Ÿ(y/N): ").strip().lower()
                if response != 'y':
                    logger.info("ç”¨æˆ·å–æ¶ˆè¿ç§»")
                    return False

        logger.info("å‰ææ¡ä»¶æ£€æŸ¥é€šè¿‡")
        return True

    def backup_existing_structure(self) -> bool:
        """å¤‡ä»½ç°æœ‰ç›®å½•ç»“æ„

        Returns:
            å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        if self.dry_run:
            logger.info("[DRY RUN] è·³è¿‡å¤‡ä»½æ­¥éª¤")
            return True

        logger.info("åˆ›å»ºç°æœ‰ç»“æ„çš„å¤‡ä»½...")

        try:
            backup_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_dir = self.databases_dir.parent / f"databases_backup_{backup_timestamp}"

            # åˆ›å»ºå¤‡ä»½ç›®å½•
            backup_dir.mkdir(exist_ok=True)

            # å¤‡ä»½å‘é‡æ•°æ®åº“ç›®å½•
            if self.vector_dbs_dir.exists():
                vector_backup = backup_dir / "vector_dbs"
                shutil.copytree(self.vector_dbs_dir, vector_backup)
                logger.info(f"å‘é‡æ•°æ®åº“å¤‡ä»½å®Œæˆ: {vector_backup}")

            # å¤‡ä»½BM25ç›®å½•
            if self.bm25_dir.exists():
                bm25_backup = backup_dir / "bm25"
                shutil.copytree(self.bm25_dir, bm25_backup)
                logger.info(f"BM25æ•°æ®åº“å¤‡ä»½å®Œæˆ: {bm25_backup}")

            logger.info(f"å¤‡ä»½å®Œæˆ: {backup_dir}")
            return True

        except Exception as e:
            logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
            return False

    def create_tenant_directories(self) -> bool:
        """åˆ›å»ºç§Ÿæˆ·çº§ç›®å½•ç»“æ„

        Returns:
            åˆ›å»ºæ˜¯å¦æˆåŠŸ
        """
        logger.info("åˆ›å»ºç§Ÿæˆ·çº§ç›®å½•ç»“æ„...")

        try:
            # ä¸ºæ¯ä¸ªåœºæ™¯åˆ›å»ºé»˜è®¤ç§Ÿæˆ·ç›®å½•
            for scenario in SCENARIOS:
                # åˆ›å»ºå‘é‡æ•°æ®åº“ç§Ÿæˆ·ç›®å½•
                vector_tenant_dir = self.vector_dbs_dir / DEFAULT_TENANT_ID / scenario
                if not vector_tenant_dir.exists():
                    if not self.dry_run:
                        vector_tenant_dir.mkdir(parents=True, exist_ok=True)
                    logger.info(f"åˆ›å»ºå‘é‡æ•°æ®åº“ç›®å½•: {vector_tenant_dir}")
                    self.migration_stats["directories_created"] += 1

                # åˆ›å»ºBM25ç§Ÿæˆ·ç›®å½•
                bm25_tenant_dir = self.bm25_dir / DEFAULT_TENANT_ID / scenario
                if not bm25_tenant_dir.exists():
                    if not self.dry_run:
                        bm25_tenant_dir.mkdir(parents=True, exist_ok=True)
                    logger.info(f"åˆ›å»ºBM25ç›®å½•: {bm25_tenant_dir}")
                    self.migration_stats["directories_created"] += 1

            return True

        except Exception as e:
            logger.error(f"åˆ›å»ºç›®å½•å¤±è´¥: {e}")
            self.migration_stats["errors"].append(f"åˆ›å»ºç›®å½•å¤±è´¥: {e}")
            return False

    def migrate_vector_databases(self) -> bool:
        """è¿ç§»å‘é‡æ•°æ®åº“æ–‡ä»¶

        Returns:
            è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        logger.info("è¿ç§»å‘é‡æ•°æ®åº“æ–‡ä»¶...")

        if not self.vector_dbs_dir.exists():
            logger.warning("å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡è¿ç§»")
            return True

        try:
            # æŸ¥æ‰¾æ‰€æœ‰å‘é‡æ•°æ®åº“æ–‡ä»¶
            vector_files = []

            # æŸ¥æ‰¾ .index æ–‡ä»¶ï¼ˆFAISSç´¢å¼•ï¼‰
            for index_file in self.vector_dbs_dir.glob("*.index"):
                vector_files.append(index_file)

            # æŸ¥æ‰¾å…¶ä»–ç›¸å…³æ–‡ä»¶
            for pattern in ["*.json", "*.pkl", "*.npy"]:
                for file in self.vector_dbs_dir.glob(pattern):
                    vector_files.append(file)

            logger.info(f"å‘ç° {len(vector_files)} ä¸ªå‘é‡æ•°æ®åº“æ–‡ä»¶")

            for file_path in vector_files:
                # ç¡®å®šç›®æ ‡åœºæ™¯
                scenario = self._determine_scenario_from_filename(file_path.name)
                if not scenario:
                    logger.warning(f"æ— æ³•ç¡®å®šåœºæ™¯ï¼Œè·³è¿‡æ–‡ä»¶: {file_path.name}")
                    continue

                # ç›®æ ‡è·¯å¾„
                target_dir = self.vector_dbs_dir / DEFAULT_TENANT_ID / scenario
                target_path = target_dir / file_path.name

                # ç§»åŠ¨æ–‡ä»¶
                if not self.dry_run:
                    if target_path.exists():
                        logger.warning(f"ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {target_path}")
                        continue

                    shutil.move(str(file_path), str(target_path))

                logger.info(f"è¿ç§»å‘é‡æ–‡ä»¶: {file_path.name} -> {target_path}")
                self.migration_stats["vector_files_moved"] += 1

            return True

        except Exception as e:
            logger.error(f"è¿ç§»å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            self.migration_stats["errors"].append(f"è¿ç§»å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
            return False

    def migrate_bm25_databases(self) -> bool:
        """è¿ç§»BM25æ•°æ®åº“æ–‡ä»¶

        Returns:
            è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        logger.info("è¿ç§»BM25æ•°æ®åº“æ–‡ä»¶...")

        if not self.bm25_dir.exists():
            logger.warning("BM25ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡è¿ç§»")
            return True

        try:
            # æŸ¥æ‰¾æ‰€æœ‰BM25æ–‡ä»¶
            bm25_files = []

            # æŸ¥æ‰¾ .pkl æ–‡ä»¶ï¼ˆBM25ç´¢å¼•ï¼‰
            for pkl_file in self.bm25_dir.glob("*.pkl"):
                bm25_files.append(pkl_file)

            # æŸ¥æ‰¾å…¶ä»–ç›¸å…³æ–‡ä»¶
            for pattern in ["*.json", "*.txt"]:
                for file in self.bm25_dir.glob(pattern):
                    bm25_files.append(file)

            logger.info(f"å‘ç° {len(bm25_files)} ä¸ªBM25æ–‡ä»¶")

            for file_path in bm25_files:
                # ç¡®å®šç›®æ ‡åœºæ™¯
                scenario = self._determine_scenario_from_filename(file_path.name)
                if not scenario:
                    logger.warning(f"æ— æ³•ç¡®å®šåœºæ™¯ï¼Œè·³è¿‡æ–‡ä»¶: {file_path.name}")
                    continue

                # ç›®æ ‡è·¯å¾„
                target_dir = self.bm25_dir / DEFAULT_TENANT_ID / scenario
                target_path = target_dir / file_path.name

                # ç§»åŠ¨æ–‡ä»¶
                if not self.dry_run:
                    if target_path.exists():
                        logger.warning(f"ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {target_path}")
                        continue

                    shutil.move(str(file_path), str(target_path))

                logger.info(f"è¿ç§»BM25æ–‡ä»¶: {file_path.name} -> {target_path}")
                self.migration_stats["bm25_files_moved"] += 1

            return True

        except Exception as e:
            logger.error(f"è¿ç§»BM25æ•°æ®åº“å¤±è´¥: {e}")
            self.migration_stats["errors"].append(f"è¿ç§»BM25æ•°æ®åº“å¤±è´¥: {e}")
            return False

    def _determine_scenario_from_filename(self, filename: str) -> str:
        """ä»æ–‡ä»¶åç¡®å®šåœºæ™¯

        Args:
            filename: æ–‡ä»¶å

        Returns:
            åœºæ™¯IDï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™è¿”å›None
        """
        filename_lower = filename.lower()

        # ç›´æ¥åŒ¹é…åœºæ™¯å
        for scenario in SCENARIOS:
            if scenario in filename_lower:
                return scenario

        # ç‰¹æ®ŠåŒ¹é…è§„åˆ™
        if "æŠ•æ ‡" in filename or "æ‹›æ ‡" in filename:
            return "tender"
        elif "ä¼ä¸š" in filename:
            return "enterprise"

        # é»˜è®¤åœºæ™¯ï¼ˆå¦‚æœæ— æ³•ç¡®å®šï¼‰
        logger.warning(f"æ— æ³•ä»æ–‡ä»¶åç¡®å®šåœºæ™¯ï¼Œä½¿ç”¨é»˜è®¤åœºæ™¯ 'tender': {filename}")
        return "tender"

    def verify_migration(self) -> bool:
        """éªŒè¯è¿ç§»ç»“æœ

        Returns:
            éªŒè¯æ˜¯å¦é€šè¿‡
        """
        logger.info("éªŒè¯è¿ç§»ç»“æœ...")

        if self.dry_run:
            logger.info("[DRY RUN] è·³è¿‡éªŒè¯æ­¥éª¤")
            return True

        try:
            # æ£€æŸ¥é»˜è®¤ç§Ÿæˆ·ç›®å½•æ˜¯å¦å­˜åœ¨
            default_vector_dir = self.vector_dbs_dir / DEFAULT_TENANT_ID
            default_bm25_dir = self.bm25_dir / DEFAULT_TENANT_ID

            if not default_vector_dir.exists():
                logger.error("é»˜è®¤ç§Ÿæˆ·å‘é‡ç›®å½•ä¸å­˜åœ¨")
                return False

            if not default_bm25_dir.exists():
                logger.error("é»˜è®¤ç§Ÿæˆ·BM25ç›®å½•ä¸å­˜åœ¨")
                return False

            # ç»Ÿè®¡è¿ç§»åçš„æ–‡ä»¶æ•°é‡
            total_files = 0
            for scenario in SCENARIOS:
                scenario_vector_dir = default_vector_dir / scenario
                scenario_bm25_dir = default_bm25_dir / scenario

                if scenario_vector_dir.exists():
                    vector_files = list(scenario_vector_dir.glob("*"))
                    total_files += len(vector_files)
                    logger.info(f"åœºæ™¯ {scenario} å‘é‡æ–‡ä»¶: {len(vector_files)} ä¸ª")

                if scenario_bm25_dir.exists():
                    bm25_files = list(scenario_bm25_dir.glob("*"))
                    total_files += len(bm25_files)
                    logger.info(f"åœºæ™¯ {scenario} BM25æ–‡ä»¶: {len(bm25_files)} ä¸ª")

            logger.info(f"è¿ç§»åæ€»æ–‡ä»¶æ•°: {total_files}")

            # æ£€æŸ¥åŸç›®å½•æ˜¯å¦è¿˜æœ‰é—ç•™æ–‡ä»¶
            remaining_vector_files = [f for f in self.vector_dbs_dir.glob("*")
                                    if f.is_file() and f.name != DEFAULT_TENANT_ID]
            remaining_bm25_files = [f for f in self.bm25_dir.glob("*")
                                  if f.is_file() and f.name != DEFAULT_TENANT_ID]

            if remaining_vector_files:
                logger.warning(f"å‘é‡ç›®å½•ä¸­è¿˜æœ‰ {len(remaining_vector_files)} ä¸ªæœªè¿ç§»æ–‡ä»¶")
                for f in remaining_vector_files:
                    logger.warning(f"  æœªè¿ç§»: {f.name}")

            if remaining_bm25_files:
                logger.warning(f"BM25ç›®å½•ä¸­è¿˜æœ‰ {len(remaining_bm25_files)} ä¸ªæœªè¿ç§»æ–‡ä»¶")
                for f in remaining_bm25_files:
                    logger.warning(f"  æœªè¿ç§»: {f.name}")

            logger.info("è¿ç§»éªŒè¯å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"éªŒè¯è¿ç§»å¤±è´¥: {e}")
            return False

    def print_migration_summary(self):
        """æ‰“å°è¿ç§»æ‘˜è¦"""
        logger.info("=" * 60)
        logger.info("è¿ç§»æ‘˜è¦")
        logger.info("=" * 60)
        logger.info(f"å‘é‡æ–‡ä»¶è¿ç§»æ•°é‡: {self.migration_stats['vector_files_moved']}")
        logger.info(f"BM25æ–‡ä»¶è¿ç§»æ•°é‡: {self.migration_stats['bm25_files_moved']}")
        logger.info(f"å…ƒæ•°æ®æ–‡ä»¶è¿ç§»æ•°é‡: {self.migration_stats['metadata_files_moved']}")
        logger.info(f"åˆ›å»ºç›®å½•æ•°é‡: {self.migration_stats['directories_created']}")
        logger.info(f"é”™è¯¯æ•°é‡: {len(self.migration_stats['errors'])}")

        if self.migration_stats['errors']:
            logger.error("é”™è¯¯è¯¦æƒ…:")
            for error in self.migration_stats['errors']:
                logger.error(f"  - {error}")

        logger.info("=" * 60)

    def run_migration(self) -> bool:
        """è¿è¡Œå®Œæ•´è¿ç§»æµç¨‹

        Returns:
            è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        logger.info("å¼€å§‹ç§Ÿæˆ·ç»“æ„è¿ç§»...")

        # 1. æ£€æŸ¥å‰ææ¡ä»¶
        if not self.check_prerequisites():
            logger.error("å‰ææ¡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œç»ˆæ­¢è¿ç§»")
            return False

        # 2. å¤‡ä»½ç°æœ‰ç»“æ„
        if not self.backup_existing_structure():
            logger.error("å¤‡ä»½å¤±è´¥ï¼Œç»ˆæ­¢è¿ç§»")
            return False

        # 3. åˆ›å»ºç§Ÿæˆ·ç›®å½•
        if not self.create_tenant_directories():
            logger.error("åˆ›å»ºç§Ÿæˆ·ç›®å½•å¤±è´¥ï¼Œç»ˆæ­¢è¿ç§»")
            return False

        # 4. è¿ç§»å‘é‡æ•°æ®åº“
        if not self.migrate_vector_databases():
            logger.error("è¿ç§»å‘é‡æ•°æ®åº“å¤±è´¥")
            # ç»§ç»­æ‰§è¡Œï¼Œä¸ç»ˆæ­¢

        # 5. è¿ç§»BM25æ•°æ®åº“
        if not self.migrate_bm25_databases():
            logger.error("è¿ç§»BM25æ•°æ®åº“å¤±è´¥")
            # ç»§ç»­æ‰§è¡Œï¼Œä¸ç»ˆæ­¢

        # 6. éªŒè¯è¿ç§»ç»“æœ
        if not self.verify_migration():
            logger.error("è¿ç§»éªŒè¯å¤±è´¥")
            return False

        # 7. æ‰“å°æ‘˜è¦
        self.print_migration_summary()

        if self.migration_stats['errors']:
            logger.warning("è¿ç§»å®Œæˆï¼Œä½†å­˜åœ¨é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
            return False
        else:
            logger.info("è¿ç§»æˆåŠŸå®Œæˆï¼")
            return True


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="ç§Ÿæˆ·ç»“æ„è¿ç§»è„šæœ¬")
    parser.add_argument("--data-dir", type=str, help="æ•°æ®ç›®å½•è·¯å¾„")
    parser.add_argument("--dry-run", action="store_true", help="è¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…ç§»åŠ¨æ–‡ä»¶ï¼‰")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶æ‰§è¡Œï¼ˆè·³è¿‡ç¡®è®¤ï¼‰")

    args = parser.parse_args()

    # åˆ›å»ºè¿ç§»å™¨
    data_dir = Path(args.data_dir) if args.data_dir else None
    migrator = TenantStructureMigrator(data_dir=data_dir, dry_run=args.dry_run)

    # ç¡®è®¤æ‰§è¡Œ
    if not args.force and not args.dry_run:
        print("\n" + "=" * 60)
        print("ç§Ÿæˆ·ç»“æ„è¿ç§»è„šæœ¬")
        print("=" * 60)
        print("æ­¤è„šæœ¬å°†:")
        print("1. å¤‡ä»½ç°æœ‰æ•°æ®åº“ç»“æ„")
        print("2. åˆ›å»ºç§Ÿæˆ·çº§ç›®å½•ç»“æ„")
        print("3. è¿ç§»ç°æœ‰ç´¢å¼•æ–‡ä»¶åˆ°é»˜è®¤ç§Ÿæˆ·ç›®å½•")
        print("4. éªŒè¯è¿ç§»ç»“æœ")
        print("\næ³¨æ„: æ­¤æ“ä½œä¼šä¿®æ”¹ç°æœ‰ç›®å½•ç»“æ„ï¼")
        print("å»ºè®®å…ˆä½¿ç”¨ --dry-run å‚æ•°è¿›è¡Œè¯•è¿è¡Œ")
        print("=" * 60)

        response = input("æ˜¯å¦ç»§ç»­æ‰§è¡Œè¿ç§»ï¼Ÿ(y/N): ").strip().lower()
        if response != 'y':
            print("ç”¨æˆ·å–æ¶ˆè¿ç§»")
            return

    # æ‰§è¡Œè¿ç§»
    success = migrator.run_migration()

    if success:
        print("\nğŸ‰ è¿ç§»æˆåŠŸå®Œæˆï¼")
        if not args.dry_run:
            print("ç°åœ¨å¯ä»¥å¯åŠ¨ç³»ç»Ÿæµ‹è¯•ç§Ÿæˆ·éš”ç¦»åŠŸèƒ½")
    else:
        print("\nâŒ è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")
        sys.exit(1)


if __name__ == "__main__":
    main()
