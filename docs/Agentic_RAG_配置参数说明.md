# Agentic RAG ç³»ç»Ÿé…ç½®å‚æ•°è¯´æ˜

## ğŸ“‹ ç›®å½•

- [1. ç¯å¢ƒå˜é‡é…ç½®](#1-ç¯å¢ƒå˜é‡é…ç½®)
- [2. æ ¸å¿ƒæ¨¡å—é…ç½®](#2-æ ¸å¿ƒæ¨¡å—é…ç½®)
- [3. åœºæ™¯é…ç½®](#3-åœºæ™¯é…ç½®)
- [4. æ€§èƒ½è°ƒä¼˜å‚æ•°](#4-æ€§èƒ½è°ƒä¼˜å‚æ•°)
- [5. ç¼“å­˜é…ç½®](#5-ç¼“å­˜é…ç½®)
- [6. æ•°æ®åº“é…ç½®](#6-æ•°æ®åº“é…ç½®)

---

## 1. ç¯å¢ƒå˜é‡é…ç½®

### 1.1 å¿…éœ€ç¯å¢ƒå˜é‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå‚è€ƒ `config_template.env`ï¼‰ï¼š

```bash
# DashScope API é…ç½®
DASHSCOPE_API_KEY=your_api_key_here

# æ•°æ®ç›®å½•é…ç½®
DATA_DIR=data/stock_data

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=logs/system.log
```

---

### 1.2 å¯é€‰ç¯å¢ƒå˜é‡

```bash
# API è¶…æ—¶è®¾ç½®ï¼ˆç§’ï¼‰
API_TIMEOUT=30

# æœ€å¤§é‡è¯•æ¬¡æ•°
MAX_RETRIES=3

# æ‰¹å¤„ç†å¤§å°
BATCH_SIZE=10

# ç¼“å­˜ç›®å½•
CACHE_DIR=.cache

# ä¸´æ—¶æ–‡ä»¶ç›®å½•
TEMP_DIR=.temp
```

---

## 2. æ ¸å¿ƒæ¨¡å—é…ç½®

### 2.1 BM25Retriever é…ç½®

**ä½ç½®**: `src/retrieval/bm25_retriever.py`

```python
class BM25Retriever:
    def __init__(self, scenario_id: str):
        # é…ç½®å‚æ•°
        self.scenario_id = scenario_id  # åœºæ™¯ID
        self.bm25_dir = Path(f"data/databases/bm25/")  # BM25ç´¢å¼•ç›®å½•
```

**å¯è°ƒå‚æ•°**:
- `k1` (float): BM25ç®—æ³•å‚æ•°ï¼Œæ§åˆ¶è¯é¢‘é¥±å’Œåº¦ï¼Œé»˜è®¤1.5
- `b` (float): BM25ç®—æ³•å‚æ•°ï¼Œæ§åˆ¶æ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–ï¼Œé»˜è®¤0.75

**è°ƒä¼˜å»ºè®®**:
- çŸ­æ–‡æ¡£ï¼šé™ä½ `b` å€¼ï¼ˆ0.5-0.6ï¼‰
- é•¿æ–‡æ¡£ï¼šæé«˜ `b` å€¼ï¼ˆ0.8-0.9ï¼‰
- æé«˜å¬å›ç‡ï¼šé™ä½ `k1` å€¼
- æé«˜ç²¾ç¡®ç‡ï¼šæé«˜ `k1` å€¼

---

### 2.2 VectorRetriever é…ç½®

**ä½ç½®**: `src/retrieval/vector_retriever.py`

```python
class VectorRetriever:
    def __init__(self, scenario_id: str):
        self.scenario_id = scenario_id
        self.vector_db_dir = Path(f"data/databases/vector_dbs/")
        self.embedding_model = "text-embedding-v3"  # åµŒå…¥æ¨¡å‹
```

**å¯è°ƒå‚æ•°**:
- `min_similarity` (float): æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œé»˜è®¤0.5
- `embedding_model` (str): åµŒå…¥æ¨¡å‹åç§°
  - `text-embedding-v1`: æ—§ç‰ˆï¼Œ1536ç»´
  - `text-embedding-v3`: æ–°ç‰ˆï¼Œ1536ç»´ï¼Œæ€§èƒ½æ›´å¥½

**è°ƒä¼˜å»ºè®®**:
- æé«˜ç²¾ç¡®ç‡ï¼šæé«˜ `min_similarity`ï¼ˆ0.6-0.7ï¼‰
- æé«˜å¬å›ç‡ï¼šé™ä½ `min_similarity`ï¼ˆ0.3-0.4ï¼‰
- ä½¿ç”¨ `text-embedding-v3` è·å¾—æ›´å¥½çš„è¯­ä¹‰ç†è§£

---

### 2.3 HybridRetriever é…ç½®

**ä½ç½®**: `src/retrieval/hybrid_retriever.py`

```python
class HybridRetriever:
    def __init__(self, scenario_id: str):
        self.scenario_id = scenario_id
        self.reranker = RRFReranker(k=60)  # RRFå‚æ•°
```

**å¯è°ƒå‚æ•°**:
- `bm25_weight` (float): BM25æƒé‡ï¼Œé»˜è®¤0.5
- `vector_weight` (float): å‘é‡æ£€ç´¢æƒé‡ï¼Œé»˜è®¤0.5
- `rrf_k` (int): RRFç®—æ³•å‚æ•°ï¼Œé»˜è®¤60

**æƒé‡è°ƒä¼˜**:
```python
# åœºæ™¯1ï¼šå…³é”®è¯åŒ¹é…æ›´é‡è¦ï¼ˆæ‹›æŠ•æ ‡ï¼‰
retriever.retrieve(
    question="...",
    bm25_weight=0.6,
    vector_weight=0.4
)

# åœºæ™¯2ï¼šè¯­ä¹‰ç†è§£æ›´é‡è¦ï¼ˆä¼ä¸šç®¡ç†ï¼‰
retriever.retrieve(
    question="...",
    bm25_weight=0.4,
    vector_weight=0.6
)

# åœºæ™¯3ï¼šå¹³è¡¡æ¨¡å¼
retriever.retrieve(
    question="...",
    bm25_weight=0.5,
    vector_weight=0.5
)
```

**RRFå‚æ•°è°ƒä¼˜**:
- `k` å€¼è¶Šå¤§ï¼Œæ’åé åçš„æ–‡æ¡£æƒé‡è¶Šå°
- æ¨èèŒƒå›´ï¼š40-80
- é»˜è®¤60é€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯

---

### 2.4 RoutingAgent é…ç½®

**ä½ç½®**: `src/agents/routing_agent.py`

```python
class RoutingAgent:
    def __init__(self, scenario_id: str):
        self.scenario_id = scenario_id
        self.llm_model = "qwen-turbo-latest"  # LLMæ¨¡å‹
        self.keyword_library = {...}  # å…³é”®è¯åº“
```

**LLMæ¨¡å‹é€‰æ‹©**:
```python
# å¿«é€Ÿæ¨¡å¼ï¼ˆä½æˆæœ¬ï¼‰
agent = RoutingAgent(scenario_id="tender")
agent.llm_model = "qwen-turbo-latest"

# å¹³è¡¡æ¨¡å¼ï¼ˆæ¨èï¼‰
agent.llm_model = "qwen-plus"

# é«˜ç²¾åº¦æ¨¡å¼ï¼ˆé«˜æˆæœ¬ï¼‰
agent.llm_model = "qwen-max"
```

**å…³é”®è¯åº“é…ç½®**:
```python
keyword_library = {
    "tender": {
        "budget": ["é¢„ç®—", "æŠ¥ä»·", "ä»·æ ¼", "é‡‘é¢"],
        "deadline": ["æˆªæ­¢", "æœŸé™", "æ—¶é—´", "æ—¥æœŸ"],
        "requirement": ["è¦æ±‚", "æ¡ä»¶", "èµ„æ ¼"],
        "technical": ["æŠ€æœ¯", "è§„æ ¼", "å‚æ•°"]
    },
    "enterprise": {
        "policy": ["æ”¿ç­–", "åˆ¶åº¦", "è§„å®š"],
        "process": ["æµç¨‹", "æ­¥éª¤", "ç¨‹åº"],
        "benefit": ["ç¦åˆ©", "å¾…é‡", "è¡¥è´´"],
        "training": ["åŸ¹è®­", "å­¦ä¹ ", "å‘å±•"]
    }
}
```

---

### 2.5 LayeredNavigator é…ç½®

**ä½ç½®**: `src/retrieval/layered_navigator.py`

```python
class LayeredNavigator:
    def navigate(
        self,
        chunks: List[Dict],
        question: str,
        max_rounds: int = 3,      # æœ€å¤§å¯¼èˆªè½®æ•°
        target_tokens: int = 2000  # ç›®æ ‡Tokenæ•°
    ):
        ...
```

**å‚æ•°è°ƒä¼˜**:
```python
# çŸ­é—®é¢˜ï¼ˆç®€å•æŸ¥è¯¢ï¼‰
navigator.navigate(
    chunks=chunks,
    question="é¢„ç®—æ˜¯å¤šå°‘ï¼Ÿ",
    max_rounds=2,
    target_tokens=1000
)

# å¤æ‚é—®é¢˜ï¼ˆéœ€è¦æ›´å¤šä¸Šä¸‹æ–‡ï¼‰
navigator.navigate(
    chunks=chunks,
    question="è¯·è¯¦ç»†è¯´æ˜é¡¹ç›®çš„æŠ€æœ¯è¦æ±‚å’Œå®æ–½æ–¹æ¡ˆ",
    max_rounds=4,
    target_tokens=3000
)

# é»˜è®¤é…ç½®ï¼ˆå¹³è¡¡ï¼‰
navigator.navigate(
    chunks=chunks,
    question="...",
    max_rounds=3,
    target_tokens=2000
)
```

**Tokenä¼°ç®—é…ç½®**:
```python
# ç®€å•ä¼°ç®—ï¼ˆå­—ç¬¦æ•° Ã— 1.5ï¼‰
def estimate_tokens_simple(text: str) -> int:
    return int(len(text) * 1.5)

# ç²¾ç¡®ä¼°ç®—ï¼ˆä½¿ç”¨tiktokenï¼‰
import tiktoken
enc = tiktoken.get_encoding("cl100k_base")
def estimate_tokens_accurate(text: str) -> int:
    return len(enc.encode(text))
```

---

### 2.6 SmartCache é…ç½®

**ä½ç½®**: `src/cache/smart_cache.py`

```python
class SmartCache:
    def __init__(
        self,
        max_size: int = 1000,           # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        exact_ttl_days: int = 7,        # ç²¾ç¡®ç¼“å­˜TTLï¼ˆå¤©ï¼‰
        semantic_ttl_days: int = 3,     # è¯­ä¹‰ç¼“å­˜TTLï¼ˆå¤©ï¼‰
        semantic_threshold: float = 0.95 # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
    ):
        ...
```

**é…ç½®å»ºè®®**:
```python
# å°å‹ç³»ç»Ÿï¼ˆ< 100 ç”¨æˆ·ï¼‰
cache = SmartCache(
    max_size=500,
    exact_ttl_days=7,
    semantic_ttl_days=3,
    semantic_threshold=0.95
)

# ä¸­å‹ç³»ç»Ÿï¼ˆ100-1000 ç”¨æˆ·ï¼‰
cache = SmartCache(
    max_size=2000,
    exact_ttl_days=14,
    semantic_ttl_days=7,
    semantic_threshold=0.93
)

# å¤§å‹ç³»ç»Ÿï¼ˆ> 1000 ç”¨æˆ·ï¼‰
cache = SmartCache(
    max_size=5000,
    exact_ttl_days=30,
    semantic_ttl_days=14,
    semantic_threshold=0.90
)
```

**è¯­ä¹‰é˜ˆå€¼è°ƒä¼˜**:
- `0.95-1.0`: éå¸¸ä¸¥æ ¼ï¼Œåªç¼“å­˜å‡ ä¹ç›¸åŒçš„é—®é¢˜
- `0.90-0.95`: æ¨èèŒƒå›´ï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œå‘½ä¸­ç‡
- `0.85-0.90`: å®½æ¾ï¼Œæé«˜å‘½ä¸­ç‡ä½†å¯èƒ½é™ä½å‡†ç¡®æ€§
- `< 0.85`: ä¸æ¨èï¼Œå¯èƒ½è¿”å›ä¸ç›¸å…³ç­”æ¡ˆ

---

### 2.7 AnswerVerifier é…ç½®

**ä½ç½®**: `src/verification/answer_verifier.py`

```python
class AnswerVerifier:
    def __init__(self):
        self.llm_model = "qwen-plus"  # LLMéªŒè¯æ¨¡å‹
        self.citation_patterns = [...]  # å¼•ç”¨æ¨¡å¼
```

**å¼•ç”¨æ¨¡å¼é…ç½®**:
```python
citation_patterns = [
    r'ç¬¬(\d+)é¡µ',           # "ç¬¬3é¡µ"
    r'ç¬¬(\d+)-(\d+)é¡µ',     # "ç¬¬3-5é¡µ"
    r'(?:è§|å‚è§|å‚è€ƒ)ç¬¬(\d+)é¡µ',  # "å‚è§ç¬¬3é¡µ"
    r'æ ¹æ®ç¬¬(\d+)é¡µ',       # "æ ¹æ®ç¬¬3é¡µ"
    r'\[(\d+)\]',           # "[3]"
    r'é¡µç [ï¼š:]\s*(\d+)',   # "é¡µç ï¼š3"
]
```

**éªŒè¯ä¸¥æ ¼åº¦é…ç½®**:
```python
# ä¸¥æ ¼æ¨¡å¼ï¼ˆé«˜å‡†ç¡®æ€§ï¼‰
verifier.min_confidence = 0.8
verifier.require_citation = True

# å®½æ¾æ¨¡å¼ï¼ˆé«˜å¬å›ç‡ï¼‰
verifier.min_confidence = 0.6
verifier.require_citation = False

# å¹³è¡¡æ¨¡å¼ï¼ˆæ¨èï¼‰
verifier.min_confidence = 0.7
verifier.require_citation = True
```

---

## 3. åœºæ™¯é…ç½®

### 3.1 åœºæ™¯å®šä¹‰

**ä½ç½®**: `src/models/scenario_models.py`

```python
DEFAULT_SCENARIO_CONFIGS = {
    "tender": {
        "id": "tender",
        "name": "æ‹›æŠ•æ ‡",
        "description": "æ‹›æŠ•æ ‡æ–‡ä»¶åˆ†æä¸é—®ç­”",
        "ui_config": {
            "theme_color": "#3B82F6",
            "welcome_title": "æ‹›æŠ•æ ‡æ™ºèƒ½åŠ©æ‰‹",
            "welcome_message": "æˆ‘å¯ä»¥å¸®æ‚¨åˆ†ææ‹›æŠ•æ ‡æ–‡ä»¶..."
        },
        "preset_questions": [
            "é¡¹ç›®é¢„ç®—æ˜¯å¤šå°‘ï¼Ÿ",
            "æˆªæ­¢æ—¥æœŸæ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ",
            "æœ‰å“ªäº›æŠ€æœ¯è¦æ±‚ï¼Ÿ"
        ],
        "document_types": [
            "æ‹›æ ‡æ–‡ä»¶",
            "æŠ€æœ¯è§„èŒƒ",
            "åˆåŒæ¨¡æ¿"
        ],
        "prompt_templates": {
            "system": "ä½ æ˜¯ä¸“ä¸šçš„æ‹›æŠ•æ ‡åˆ†æå¸ˆ...",
            "user": "åŸºäºä»¥ä¸‹æ–‡æ¡£å›ç­”é—®é¢˜..."
        }
    }
}
```

---

### 3.2 æ·»åŠ æ–°åœºæ™¯

**æ­¥éª¤**:

1. **å®šä¹‰åœºæ™¯é…ç½®**:
```python
# src/models/scenario_models.py
DEFAULT_SCENARIO_CONFIGS["new_scenario"] = {
    "id": "new_scenario",
    "name": "æ–°åœºæ™¯åç§°",
    "description": "åœºæ™¯æè¿°",
    "ui_config": {
        "theme_color": "#10B981",
        "welcome_title": "æ–°åœºæ™¯åŠ©æ‰‹",
        "welcome_message": "æ¬¢è¿ä½¿ç”¨..."
    },
    "preset_questions": [
        "é—®é¢˜1",
        "é—®é¢˜2"
    ],
    "document_types": [
        "æ–‡æ¡£ç±»å‹1",
        "æ–‡æ¡£ç±»å‹2"
    ],
    "prompt_templates": {
        "system": "ä½ æ˜¯ä¸“ä¸šçš„...",
        "user": "åŸºäºä»¥ä¸‹æ–‡æ¡£..."
    }
}
```

2. **æ›´æ–°å‰ç«¯åœºæ™¯åˆ—è¡¨**:
```typescript
// frontend-next/contexts/scenario-context.tsx
const defaultScenarios = [
  {
    id: 'tender',
    name: 'æ‹›æŠ•æ ‡',
    // ...
  },
  {
    id: 'new_scenario',
    name: 'æ–°åœºæ™¯åç§°',
    // ...
  }
];
```

3. **æ›´æ–°è·¯ç”±ä»£ç†å…³é”®è¯åº“**:
```python
# src/agents/routing_agent.py
self.keyword_library = {
    "new_scenario": {
        "category1": ["å…³é”®è¯1", "å…³é”®è¯2"],
        "category2": ["å…³é”®è¯3", "å…³é”®è¯4"]
    }
}
```

---

## 4. æ€§èƒ½è°ƒä¼˜å‚æ•°

### 4.1 æ£€ç´¢æ€§èƒ½

```python
# config.py æˆ–è¿è¡Œæ—¶é…ç½®
RETRIEVAL_CONFIG = {
    "bm25_top_k": 15,        # BM25åˆç­›æ•°é‡
    "vector_top_k": 15,      # å‘é‡æ£€ç´¢æ•°é‡
    "hybrid_top_k": 10,      # æ··åˆæ£€ç´¢æœ€ç»ˆæ•°é‡
    "min_similarity": 0.5,   # æœ€å°ç›¸ä¼¼åº¦
    "use_cache": True,       # å¯ç”¨ç¼“å­˜
}
```

---

### 4.2 LLMè°ƒç”¨ä¼˜åŒ–

```python
LLM_CONFIG = {
    "temperature": 0.3,      # æ¸©åº¦ï¼ˆ0-1ï¼‰ï¼Œè¶Šä½è¶Šç¡®å®š
    "max_tokens": 1000,      # æœ€å¤§ç”ŸæˆTokenæ•°
    "top_p": 0.9,            # æ ¸é‡‡æ ·å‚æ•°
    "timeout": 30,           # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    "max_retries": 3,        # æœ€å¤§é‡è¯•æ¬¡æ•°
}
```

**æ¨¡å‹é€‰æ‹©ç­–ç•¥**:
```python
def select_model(question: str, chunks: List[Dict]) -> str:
    """æ ¹æ®é—®é¢˜å¤æ‚åº¦é€‰æ‹©æ¨¡å‹"""

    # ç®€å•é—®é¢˜ï¼ˆæœ‰æ˜ç¡®ç­”æ¡ˆï¼‰
    if len(chunks) > 0 and is_simple_question(question):
        return "qwen-turbo-latest"  # å¿«é€Ÿã€ä¾¿å®œ

    # å¤æ‚é—®é¢˜ï¼ˆéœ€è¦æ¨ç†ï¼‰
    if requires_reasoning(question):
        return "qwen-max"  # å‡†ç¡®ã€æ˜‚è´µ

    # é»˜è®¤
    return "qwen-plus"  # å¹³è¡¡
```

---

### 4.3 æ‰¹å¤„ç†é…ç½®

```python
BATCH_CONFIG = {
    "embedding_batch_size": 10,   # åµŒå…¥æ‰¹å¤„ç†å¤§å°
    "max_concurrent_requests": 5,  # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    "batch_timeout": 60,           # æ‰¹å¤„ç†è¶…æ—¶ï¼ˆç§’ï¼‰
}
```

---

### 4.4 Tokenæ§åˆ¶

```python
TOKEN_CONFIG = {
    "max_context_tokens": 8000,    # æœ€å¤§ä¸Šä¸‹æ–‡Token
    "target_context_tokens": 2000,  # ç›®æ ‡ä¸Šä¸‹æ–‡Token
    "max_answer_tokens": 1000,      # æœ€å¤§ç­”æ¡ˆToken
    "reserve_tokens": 500,          # é¢„ç•™Tokenï¼ˆç”¨äºæç¤ºè¯ï¼‰
}
```

---

## 5. ç¼“å­˜é…ç½®

### 5.1 ç¼“å­˜ç­–ç•¥

```python
CACHE_CONFIG = {
    # ç²¾ç¡®ç¼“å­˜
    "exact_cache": {
        "enabled": True,
        "max_size": 1000,
        "ttl_days": 7,
        "eviction_policy": "LRU"  # LRU, LFU, FIFO
    },

    # è¯­ä¹‰ç¼“å­˜
    "semantic_cache": {
        "enabled": True,
        "max_size": 500,
        "ttl_days": 3,
        "threshold": 0.95,
        "use_faiss": False  # æ˜¯å¦ä½¿ç”¨FAISSåŠ é€Ÿ
    },

    # ç¼“å­˜é¢„çƒ­
    "warmup": {
        "enabled": True,
        "questions_file": "data/common_questions.json"
    }
}
```

---

### 5.2 ç¼“å­˜é¢„çƒ­

**é…ç½®æ–‡ä»¶**: `data/common_questions.json`

```json
[
  {
    "question": "é¡¹ç›®é¢„ç®—æ˜¯å¤šå°‘ï¼Ÿ",
    "answer": "...",
    "confidence": 0.9
  },
  {
    "question": "æˆªæ­¢æ—¥æœŸæ˜¯ä»€ä¹ˆæ—¶å€™ï¼Ÿ",
    "answer": "...",
    "confidence": 0.85
  }
]
```

**é¢„çƒ­ä»£ç **:
```python
from src.cache.smart_cache import SmartCache
import json

cache = SmartCache()

# åŠ è½½å¸¸è§é—®é¢˜
with open("data/common_questions.json") as f:
    common_qa = json.load(f)

# é¢„çƒ­ç¼“å­˜
for qa in common_qa:
    cache.set(
        question=qa["question"],
        answer=qa,
        use_semantic=True
    )

print(f"âœ… ç¼“å­˜é¢„çƒ­å®Œæˆï¼ŒåŠ è½½ {len(common_qa)} ä¸ªé—®é¢˜")
```

---

## 6. æ•°æ®åº“é…ç½®

### 6.1 SQLiteé…ç½®

**ä½ç½®**: `backend/database.py`

```python
DATABASE_URL = "sqlite:///data/stock_data/databases/stock_rag.db"

engine = create_engine(
    DATABASE_URL,
    connect_args={"check_same_thread": False},
    pool_size=10,           # è¿æ¥æ± å¤§å°
    max_overflow=20,        # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
    pool_timeout=30,        # è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
    pool_recycle=3600       # è¿æ¥å›æ”¶æ—¶é—´ï¼ˆç§’ï¼‰
)
```

---

### 6.2 ç´¢å¼•ä¼˜åŒ–

```sql
-- ä¸ºå¸¸ç”¨æŸ¥è¯¢åˆ›å»ºç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_documents_scenario
ON documents(scenario_id);

CREATE INDEX IF NOT EXISTS idx_documents_status
ON documents(status);

CREATE INDEX IF NOT EXISTS idx_documents_created
ON documents(created_at);

-- å¤åˆç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_documents_scenario_status
ON documents(scenario_id, status);
```

---

## ğŸ“Š æ¨èé…ç½®

### å¼€å‘ç¯å¢ƒ

```python
# å¿«é€Ÿè¿­ä»£ï¼Œä½æˆæœ¬
CONFIG = {
    "llm_model": "qwen-turbo-latest",
    "cache_enabled": True,
    "cache_max_size": 100,
    "retrieval_top_k": 5,
    "target_tokens": 1000,
    "log_level": "DEBUG"
}
```

---

### ç”Ÿäº§ç¯å¢ƒ

```python
# é«˜æ€§èƒ½ï¼Œé«˜å‡†ç¡®æ€§
CONFIG = {
    "llm_model": "qwen-plus",
    "cache_enabled": True,
    "cache_max_size": 5000,
    "retrieval_top_k": 10,
    "target_tokens": 2000,
    "log_level": "INFO",
    "enable_monitoring": True,
    "enable_verification": True
}
```

---

## ğŸ”§ é…ç½®æ–‡ä»¶ç¤ºä¾‹

**å®Œæ•´é…ç½®æ–‡ä»¶**: `config/production.yaml`

```yaml
# APIé…ç½®
api:
  provider: dashscope
  timeout: 30
  max_retries: 3

# LLMé…ç½®
llm:
  default_model: qwen-plus
  temperature: 0.3
  max_tokens: 1000

# æ£€ç´¢é…ç½®
retrieval:
  bm25_weight: 0.5
  vector_weight: 0.5
  top_k: 10
  min_similarity: 0.5

# ç¼“å­˜é…ç½®
cache:
  enabled: true
  max_size: 5000
  exact_ttl_days: 7
  semantic_ttl_days: 3
  semantic_threshold: 0.95

# æ€§èƒ½é…ç½®
performance:
  max_concurrent_requests: 10
  batch_size: 10
  target_tokens: 2000

# æ—¥å¿—é…ç½®
logging:
  level: INFO
  file: logs/system.log
  max_size: 100MB
  backup_count: 10
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-09-30
**ç»´æŠ¤å›¢é˜Ÿ**: Agentic RAG å¼€å‘å›¢é˜Ÿ

