"""
é—®é¢˜å¤„ç†æ¨¡å—
è´Ÿè´£é—®é¢˜è§£æã€åˆ†ç±»ã€æ£€ç´¢å’Œç­”æ¡ˆç”Ÿæˆ
é›†æˆ Agentic RAG ç»„ä»¶
"""

import json
import logging
import time
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

from config import get_settings
from api_requests import APIProcessor
from data_models import Question

# Agentic RAG ç»„ä»¶
from src.retrieval.hybrid_retriever import HybridRetriever
from src.agents.routing_agent import RoutingAgent
from src.retrieval.layered_navigator import LayeredNavigator
from src.cache.smart_cache import SmartCache
from src.verification.answer_verifier import AnswerVerifier

logger = logging.getLogger(__name__)


@dataclass
class QuestionContext:
    """é—®é¢˜ä¸Šä¸‹æ–‡"""

    question_text: str
    question_type: str
    company: Optional[str] = None
    difficulty: Optional[str] = None
    category: Optional[str] = None
    relevant_chunks: List[Dict[str, Any]] = None
    metadata: Dict[str, Any] = None


class QuestionsProcessor:
    """é—®é¢˜å¤„ç†å™¨"""

    def __init__(self, api_provider: str = "dashscope", scenario_id: str = "investment", tenant_id: str = "default"):
        """åˆå§‹åŒ–é—®é¢˜å¤„ç†å™¨

        Args:
            api_provider: APIæä¾›å•†åç§°
            scenario_id: ä¸šåŠ¡åœºæ™¯ID
            tenant_id: ç§Ÿæˆ·IDï¼ˆç”¨äºæ•°æ®éš”ç¦»ï¼‰
        """
        self.settings = get_settings()
        self.api_provider = api_provider
        self.api_processor = APIProcessor(provider=api_provider)
        self.scenario_id = scenario_id
        self.tenant_id = tenant_id  # æ–°å¢ï¼šå­˜å‚¨ç§Ÿæˆ·ID

        # æ ¹æ®åœºæ™¯è®¾ç½®ä¸åŒçš„æç¤ºè¯æ¨¡æ¿
        self._setup_scenario_prompts()

        # âœ… Agentic RAG ç»„ä»¶åˆå§‹åŒ–ï¼ˆä¼ é€’ç§Ÿæˆ·ä¿¡æ¯ï¼‰
        try:
            self.hybrid_retriever = HybridRetriever(scenario_id, tenant_id=tenant_id)  # æ–°å¢ï¼šä¼ é€’ç§Ÿæˆ·ID
            self.routing_agent = RoutingAgent(scenario_id)
            self.layered_navigator = LayeredNavigator(self.routing_agent)
            self.smart_cache = SmartCache(max_size=1000)
            self.answer_verifier = AnswerVerifier()
            self.agentic_rag_enabled = True
            logger.info(f"âœ… Agentic RAG ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ (scenario: {scenario_id}, tenant: {tenant_id})")
        except Exception as e:
            logger.warning(f"âš ï¸ Agentic RAG ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é™çº§æ¨¡å¼")
            self.agentic_rag_enabled = False

    def _setup_scenario_prompts(self):
        """æ ¹æ®åœºæ™¯è®¾ç½®æç¤ºè¯æ¨¡æ¿"""
        if self.scenario_id == "investment":
            self.question_analysis_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜ï¼š{question}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦åˆ†æï¼š
1. é—®é¢˜ç±»å‹ï¼šæ˜¯äº‹å®æŸ¥è¯¢ã€åˆ†æåˆ¤æ–­è¿˜æ˜¯é¢„æµ‹å»ºè®®ï¼Ÿ
2. æ¶‰åŠå…¬å¸ï¼šå¦‚æœæåŠå…·ä½“å…¬å¸ï¼Œè¯·æå–å…¬å¸åç§°
3. é—®é¢˜éš¾åº¦ï¼šç®€å•ã€ä¸­ç­‰è¿˜æ˜¯å¤æ‚ï¼Ÿ
4. é—®é¢˜ç±»åˆ«ï¼šè´¢åŠ¡åˆ†æã€è¡Œä¸šåˆ†æã€æŠ•èµ„å»ºè®®ã€é£é™©è¯„ä¼°ç­‰

è¯·ä»¥JSONæ ¼å¼å›ç­”ï¼š
{{
    "question_type": "string",
    "companies": ["å…¬å¸å"],
    "difficulty": "medium",
    "category": "è´¢åŠ¡åˆ†æ",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
}}"""

            self.answer_generation_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆï¼Œè¯·åŸºäºæä¾›çš„ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

{context_section}

è¯·æä¾›ï¼š
1. å‡†ç¡®ã€å®¢è§‚çš„åˆ†æ
2. åŸºäºäº‹å®çš„åˆ¤æ–­
3. å¦‚æœæ¶‰åŠæŠ•èµ„å»ºè®®ï¼Œè¯·è¯´æ˜é£é™©
4. ä¿æŒä¸“ä¸šå’Œä¸­æ€§çš„è¯­è°ƒ

å›ç­”ï¼š"""

        elif self.scenario_id == "tender":
            self.question_analysis_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æ‹›æŠ•æ ‡åˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜ï¼š{question}

è¯·ä»ä»¥ä¸‹å‡ ä¸ªç»´åº¦åˆ†æï¼š
1. é—®é¢˜ç±»å‹ï¼šæ˜¯æ‹›æ ‡ä¿¡æ¯æŸ¥è¯¢ã€æŠ€æœ¯è¦æ±‚åˆ†æè¿˜æ˜¯æŠ•æ ‡ç­–ç•¥å’¨è¯¢ï¼Ÿ
2. æ¶‰åŠé¡¹ç›®ï¼šå¦‚æœæåŠå…·ä½“é¡¹ç›®ï¼Œè¯·æå–é¡¹ç›®ä¿¡æ¯
3. é—®é¢˜éš¾åº¦ï¼šç®€å•ã€ä¸­ç­‰è¿˜æ˜¯å¤æ‚ï¼Ÿ
4. é—®é¢˜ç±»åˆ«ï¼šæ‹›æ ‡è¦æ±‚ã€æŠ€æœ¯è§„èŒƒã€èµ„è´¨æ¡ä»¶ã€æ—¶é—´å®‰æ’ã€é¢„ç®—åˆ†æç­‰

è¯·ä»¥JSONæ ¼å¼å›ç­”ï¼š
{{
    "question_type": "string",
    "projects": ["é¡¹ç›®å"],
    "difficulty": "medium",
    "category": "æ‹›æ ‡è¦æ±‚",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
}}"""

            self.answer_generation_prompt = """ä½ æ˜¯ä¸“ä¸šçš„æ‹›æŠ•æ ‡åˆ†æå¸ˆï¼Œè¯·åŸºäºæä¾›çš„æ‹›æŠ•æ ‡æ–‡æ¡£ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

{context_section}

è¯·æä¾›ï¼š
1. å‡†ç¡®çš„æ‹›æŠ•æ ‡ä¿¡æ¯è§£è¯»
2. æ¸…æ™°çš„æŠ€æœ¯è¦æ±‚è¯´æ˜
3. æ˜ç¡®çš„æ—¶é—´èŠ‚ç‚¹å’Œæµç¨‹
4. å¿…è¦çš„åˆè§„æ€§æé†’
5. ä¿æŒä¸“ä¸šå’Œä¸¥è°¨çš„è¯­è°ƒ

å›ç­”ï¼š"""

        else:
            # é€šç”¨åœºæ™¯çš„æç¤ºè¯
            self.question_analysis_prompt = """è¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼š

é—®é¢˜ï¼š{question}

è¯·ä»¥JSONæ ¼å¼åˆ†æï¼š
{{
    "question_type": "string",
    "difficulty": "medium",
    "category": "general",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
}}"""

            self.answer_generation_prompt = """è¯·åŸºäºæä¾›çš„ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

é—®é¢˜ï¼š{question}

{context_section}

å›ç­”ï¼š"""

        logger.info(f"QuestionsProcessor initialized with provider: {self.api_provider}, scenario: {self.scenario_id}")

    def analyze_question(self, question: str) -> Dict[str, Any]:
        """åˆ†æé—®é¢˜ç‰¹å¾

        Args:
            question: é—®é¢˜æ–‡æœ¬

        Returns:
            é—®é¢˜åˆ†æç»“æœ
        """
        try:
            logger.debug(f"åˆ†æé—®é¢˜: {question}")

            prompt = self.question_analysis_prompt.format(question=question)

            response = self.api_processor.send_message(
                system_content="ä½ æ˜¯ä¸“ä¸šçš„é—®é¢˜åˆ†æåŠ©æ‰‹",
                human_content=prompt,
                temperature=0.1,
                max_tokens=200,
            )

            # å°è¯•è§£æJSONå“åº”
            try:
                analysis = json.loads(response)
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œè¿”å›åŸºæœ¬åˆ†æ
                analysis = {
                    "question_type": "string",
                    "companies": [],
                    "difficulty": "medium",
                    "category": "general",
                    "keywords": question.split()[:5],
                }
                logger.warning("é—®é¢˜åˆ†æJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ")

            logger.debug(f"é—®é¢˜åˆ†æå®Œæˆ: {analysis}")
            return analysis

        except Exception as e:
            logger.error(f"é—®é¢˜åˆ†æå¤±è´¥: {str(e)}")
            return {
                "question_type": "string",
                "companies": [],
                "difficulty": "medium",
                "category": "general",
                "keywords": [],
                "error": str(e),
            }

    def retrieve_relevant_context(
        self, question: str, question_analysis: Dict[str, Any], top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆAgentic RAG å®Œæ•´å®ç°ï¼‰

        Args:
            question: é—®é¢˜æ–‡æœ¬
            question_analysis: é—®é¢˜åˆ†æç»“æœ
            top_k: è¿”å›çš„æ–‡æ¡£æ•°é‡

        Returns:
            ç›¸å…³æ–‡æ¡£åˆ—è¡¨
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡: {question[:50]}")

            # å¦‚æœ Agentic RAG æœªå¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨
            if not self.agentic_rag_enabled:
                logger.warning("Agentic RAG æœªå¯ç”¨ï¼Œè·³è¿‡æ£€ç´¢")
                return []

            # âœ… ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ç¼“å­˜
            cached_result = self.smart_cache.get(question)
            if cached_result:
                logger.info("âœ… ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›")
                # ç¼“å­˜ä¸­å­˜å‚¨çš„æ˜¯å®Œæ•´ç­”æ¡ˆï¼Œè¿™é‡Œéœ€è¦è¿”å›æ–‡æ¡£å—
                # å¦‚æœç¼“å­˜ä¸­æœ‰ source_chunksï¼Œè¿”å›å®ƒ
                if "source_chunks" in cached_result:
                    return cached_result["source_chunks"]
                # å¦åˆ™è¿”å›ç©ºï¼ˆçº¯LLMç­”æ¡ˆï¼‰
                return []

            # âœ… ç¬¬äºŒæ­¥ï¼šæ··åˆæ£€ç´¢ï¼ˆBM25 + FAISS + RRFï¼‰
            logger.info("ğŸ” æ‰§è¡Œæ··åˆæ£€ç´¢...")
            retrieval_results = self.hybrid_retriever.retrieve(
                question=question,
                top_k=top_k * 3,  # åˆå§‹æ£€ç´¢æ›´å¤šå€™é€‰
                use_bm25=True,
                use_vector=True
            )

            if not retrieval_results:
                logger.warning("æ··åˆæ£€ç´¢æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                return []

            logger.info(f"æ··åˆæ£€ç´¢å®Œæˆ: æ‰¾åˆ° {len(retrieval_results)} ä¸ªå€™é€‰æ–‡æ¡£")

            # âœ… ç¬¬ä¸‰æ­¥ï¼šè·¯ç”±ä»£ç†æ™ºèƒ½ç­›é€‰
            logger.info("ğŸ§  æ‰§è¡Œæ™ºèƒ½è·¯ç”±...")
            routing_result = self.routing_agent.route_documents(
                chunks=retrieval_results,
                question=question,
                history="",
                top_k=top_k * 2  # è·¯ç”±åä¿ç•™æ›´å¤šæ–‡æ¡£ä¾›åˆ†å±‚å¯¼èˆª
            )

            if not routing_result.get("success") or not routing_result.get("chunks"):
                logger.warning("è·¯ç”±ä»£ç†ç­›é€‰å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ£€ç´¢ç»“æœ")
                selected_chunks = retrieval_results[:top_k * 2]
            else:
                selected_chunks = routing_result["chunks"]
                logger.info(
                    f"è·¯ç”±å®Œæˆ: é€‰ä¸­ {len(selected_chunks)} ä¸ªæ–‡æ¡£ "
                    f"(ç½®ä¿¡åº¦: {routing_result.get('confidence', 0):.2f})"
                )

            # âœ… ç¬¬å››æ­¥ï¼šåˆ†å±‚å¯¼èˆªï¼ˆToken æ§åˆ¶ï¼‰
            logger.info("ğŸ“Š æ‰§è¡Œåˆ†å±‚å¯¼èˆª...")
            final_chunks = self.layered_navigator.navigate(
                chunks=selected_chunks,
                question=question,
                max_rounds=3,
                target_tokens=2000
            )

            logger.info(f"åˆ†å±‚å¯¼èˆªå®Œæˆ: æœ€ç»ˆ {len(final_chunks)} ä¸ªæ–‡æ¡£å—")

            # è¿”å›æœ€ç»ˆç»“æœ
            return final_chunks[:top_k]  # ç¡®ä¿ä¸è¶…è¿‡ top_k

        except Exception as e:
            logger.error(f"æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def generate_answer(
        self,
        question: str,
        context_docs: List[Dict[str, Any]] = None,
        question_type: str = "string",
    ) -> Dict[str, Any]:
        """ç”Ÿæˆç­”æ¡ˆï¼ˆé›†æˆç­”æ¡ˆéªŒè¯å’Œç¼“å­˜ï¼‰

        Args:
            question: é—®é¢˜æ–‡æœ¬
            context_docs: ç›¸å…³æ–‡æ¡£ä¸Šä¸‹æ–‡
            question_type: é—®é¢˜ç±»å‹

        Returns:
            ç­”æ¡ˆç”Ÿæˆç»“æœ
        """
        try:
            logger.info(f"ğŸ’¬ ç”Ÿæˆç­”æ¡ˆ: {question[:50]}")

            start_time = time.time()

            # æ„å»ºä¸Šä¸‹æ–‡éƒ¨åˆ†
            if context_docs:
                context_section = "å‚è€ƒä¿¡æ¯ï¼š\n"
                for i, doc in enumerate(context_docs[:5]):  # æœ€å¤šä½¿ç”¨5ä¸ªæ–‡æ¡£
                    page = doc.get('page', 'æœªçŸ¥')
                    text = doc.get('text', '')[:300]  # é™åˆ¶é•¿åº¦
                    context_section += f"\nã€æ–‡æ¡£{i+1}ã€‘(ç¬¬{page}é¡µ)\n{text}...\n"
            else:
                context_section = "è¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†å›ç­”ã€‚"

            # ç”Ÿæˆå®Œæ•´æç¤ºè¯
            prompt = self.answer_generation_prompt.format(
                question=question, context_section=context_section
            )

            # æ ¹æ®åœºæ™¯é€‰æ‹©system content
            system_content_map = {
                "tender": "ä½ æ˜¯ä¸“ä¸šçš„æ‹›æŠ•æ ‡åˆ†æå¸ˆ",
                "enterprise": "ä½ æ˜¯ä¸“ä¸šçš„ä¼ä¸šç®¡ç†é¡¾é—®",
                "investment": "ä½ æ˜¯ä¸“ä¸šçš„æŠ•èµ„åˆ†æå¸ˆ"
            }
            system_content = system_content_map.get(self.scenario_id, "ä½ æ˜¯ä¸“ä¸šçš„AIåŠ©æ‰‹")

            # è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆï¼ˆä½¿ç”¨ qwen-plus å¹³è¡¡è´¨é‡å’Œæˆæœ¬ï¼‰
            response = self.api_processor.send_message(
                system_content=system_content,
                human_content=prompt,
                temperature=0.3,
                max_tokens=1000,
                model="qwen-plus"  # ä½¿ç”¨ qwen-plus
            )

            processing_time = time.time() - start_time

            # âœ… ç­”æ¡ˆéªŒè¯ï¼ˆå¦‚æœå¯ç”¨ Agentic RAGï¼‰
            verification_result = None
            if self.agentic_rag_enabled and context_docs:
                try:
                    logger.info("ğŸ” æ‰§è¡Œç­”æ¡ˆéªŒè¯...")
                    verification_result = self.answer_verifier.verify_answer(
                        answer=response,
                        source_chunks=context_docs,
                        question=question
                    )
                    logger.info(
                        f"éªŒè¯å®Œæˆ: valid={verification_result.get('is_valid')}, "
                        f"confidence={verification_result.get('confidence')}"
                    )
                except Exception as e:
                    logger.warning(f"ç­”æ¡ˆéªŒè¯å¤±è´¥: {e}")
                    verification_result = None

            # è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
            if verification_result:
                confidence = verification_result.get("confidence", 0.7)
            else:
                # åŸºäºæ–‡æ¡£æ•°é‡çš„ç®€å•ç½®ä¿¡åº¦
                if context_docs:
                    confidence = min(0.8, 0.5 + len(context_docs) * 0.05)
                else:
                    confidence = 0.5

            relevant_pages = [doc.get("page", 0) for doc in (context_docs or [])]

            result = {
                "success": True,
                "answer": response,
                "reasoning": verification_result.get("reasoning", "åŸºäºLLMåˆ†æç”Ÿæˆ") if verification_result else "åŸºäºLLMåˆ†æç”Ÿæˆ",
                "relevant_pages": relevant_pages,
                "confidence": confidence,
                "processing_time": processing_time,
                "context_docs_count": len(context_docs) if context_docs else 0,
                "verification": verification_result if verification_result else {"status": "skipped"}
            }

            # âœ… å­˜å…¥ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ Agentic RAGï¼‰
            if self.agentic_rag_enabled:
                try:
                    cache_data = {
                        **result,
                        "source_chunks": context_docs,
                        "question": question
                    }
                    self.smart_cache.set(question, cache_data, use_semantic=True)
                    logger.debug("âœ… ç­”æ¡ˆå·²ç¼“å­˜")
                except Exception as e:
                    logger.warning(f"ç¼“å­˜å­˜å‚¨å¤±è´¥: {e}")

            logger.info(f"ç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’, ç½®ä¿¡åº¦: {confidence:.2f}")

            return result

        except Exception as e:
            logger.error(f"ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "answer": "",
                "reasoning": "",
                "relevant_pages": [],
                "confidence": 0.1,
                "processing_time": 0,
                "context_docs_count": 0,
            }

    def process_question(
        self,
        question: str,
        company: Optional[str] = None,
        question_type: str = "string",
    ) -> Dict[str, Any]:
        """å®Œæ•´çš„é—®é¢˜å¤„ç†æµç¨‹

        Args:
            question: é—®é¢˜æ–‡æœ¬
            company: ç›®æ ‡å…¬å¸
            question_type: é—®é¢˜ç±»å‹

        Returns:
            å®Œæ•´çš„å¤„ç†ç»“æœ
        """
        start_time = time.time()

        try:
            logger.info(f"å¼€å§‹å¤„ç†é—®é¢˜: {question}")

            # 1. é—®é¢˜åˆ†æ
            analysis = self.analyze_question(question)

            # 2. æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
            context_docs = self.retrieve_relevant_context(question, analysis)

            # 3. ç”Ÿæˆç­”æ¡ˆ
            answer_result = self.generate_answer(question, context_docs, question_type)

            # 4. æ•´åˆç»“æœ
            total_time = time.time() - start_time

            result = {
                "question": question,
                "company": company,
                "question_type": question_type,
                "analysis": analysis,
                "total_processing_time": total_time,
                **answer_result,
            }

            logger.info(f"é—®é¢˜å¤„ç†å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")

            return result

        except Exception as e:
            logger.error(f"é—®é¢˜å¤„ç†å¤±è´¥: {str(e)}")
            return {
                "question": question,
                "company": company,
                "question_type": question_type,
                "success": False,
                "error": str(e),
                "answer": "",
                "reasoning": "",
                "relevant_pages": [],
                "confidence": "low",
                "total_processing_time": time.time() - start_time,
            }

    def get_agentic_rag_stats(self) -> Dict[str, Any]:
        """
        è·å– Agentic RAG ç»„ä»¶ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.agentic_rag_enabled:
            return {"enabled": False, "message": "Agentic RAG æœªå¯ç”¨"}

        try:
            return {
                "enabled": True,
                "cache_stats": self.smart_cache.get_stats(),
                "retrieval_stats": self.hybrid_retriever.get_stats(),
                "scenario_id": self.scenario_id
            }
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"enabled": True, "error": str(e)}

    def batch_process_questions(
        self, questions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æ‰¹é‡å¤„ç†é—®é¢˜

        Args:
            questions: é—®é¢˜åˆ—è¡¨

        Returns:
            æ‰¹é‡å¤„ç†ç»“æœ
        """
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(questions)} ä¸ªé—®é¢˜")

        results = {
            "total_questions": len(questions),
            "successful": 0,
            "failed": 0,
            "answers": [],
            "total_time": 0,
        }

        start_time = time.time()

        for i, question_item in enumerate(questions):
            try:
                logger.info(f"å¤„ç†é—®é¢˜ {i+1}/{len(questions)}")

                # æå–é—®é¢˜ä¿¡æ¯
                question_text = question_item.get("question_text", "")
                question_type = question_item.get("question_type", "string")
                company = question_item.get("target_companies", [None])[0]

                # å¤„ç†é—®é¢˜
                result = self.process_question(question_text, company, question_type)

                # æ·»åŠ é—®é¢˜ID
                result["question_id"] = question_item.get("question_id", f"q_{i}")

                # è®°å½•ç»“æœ
                if result["success"]:
                    results["successful"] += 1
                else:
                    results["failed"] += 1

                results["answers"].append(result)

            except Exception as e:
                logger.error(f"å¤„ç†é—®é¢˜ {i+1} å¤±è´¥: {str(e)}")
                results["failed"] += 1
                results["answers"].append(
                    {
                        "question_id": question_item.get("question_id", f"q_{i}"),
                        "question": question_item.get("question_text", ""),
                        "success": False,
                        "error": str(e),
                    }
                )

        results["total_time"] = time.time() - start_time
        results["success"] = results["failed"] == 0

        logger.info(
            f"æ‰¹é‡å¤„ç†å®Œæˆ: {results['successful']}/{results['total_questions']} æˆåŠŸ"
        )

        return results

    def load_questions_from_file(self, questions_file: Path) -> List[Dict[str, Any]]:
        """ä»æ–‡ä»¶åŠ è½½é—®é¢˜

        Args:
            questions_file: é—®é¢˜æ–‡ä»¶è·¯å¾„

        Returns:
            é—®é¢˜åˆ—è¡¨
        """
        try:
            with open(questions_file, "r", encoding="utf-8") as f:
                questions = json.load(f)

            logger.info(f"ä»æ–‡ä»¶åŠ è½½ {len(questions)} ä¸ªé—®é¢˜: {questions_file}")
            return questions

        except Exception as e:
            logger.error(f"åŠ è½½é—®é¢˜æ–‡ä»¶å¤±è´¥: {str(e)}")
            return []

    def save_answers(self, results: Dict[str, Any], output_file: Path):
        """ä¿å­˜ç­”æ¡ˆåˆ°æ–‡ä»¶

        Args:
            results: å¤„ç†ç»“æœ
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

            logger.info(f"ç­”æ¡ˆå·²ä¿å­˜åˆ°: {output_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜ç­”æ¡ˆå¤±è´¥: {str(e)}")


# ä¾¿æ·å‡½æ•°
def process_single_question(
    question: str, company: Optional[str] = None, api_provider: str = "dashscope", scenario_id: str = "investment"
) -> Dict[str, Any]:
    """å¤„ç†å•ä¸ªé—®é¢˜çš„ä¾¿æ·å‡½æ•°"""
    processor = QuestionsProcessor(api_provider=api_provider, scenario_id=scenario_id)
    return processor.process_question(question, company)


def create_questions_processor(api_provider: str = "dashscope", scenario_id: str = "investment") -> QuestionsProcessor:
    """åˆ›å»ºé—®é¢˜å¤„ç†å™¨çš„ä¾¿æ·å‡½æ•°"""
    return QuestionsProcessor(api_provider=api_provider, scenario_id=scenario_id)
